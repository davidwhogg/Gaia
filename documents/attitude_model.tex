% This file is part of the Gaia project.
% Copyright 2012 David W. Hogg (NYU).

\documentclass[12pt]{article}

\newcommand{\project}[1]{\textsl{#1}}
\newcommand{\gaia}{\project{Gaia}}

\begin{document}\sloppy\sloppypar\raggedbottom

\section*{Controlling the complexity of the attitude\\
  model for \gaia\ (or any other spacecraft)}

\noindent
David W. Hogg (NYU) \\
2012-02-25

\begin{abstract}
A data-driven model of spacecraft attitude is a key component of the
\gaia\ data analysis pipeline.  On-board drift scanning effectively
removes attitude information on time scales shorter than a few
seconds, but beyond that it is not known how much freedom must be
given to the attitude model; a bad choice of model complexity will
reduce the precision of the final astrometric catalog through either
over-fitting or under-fitting.  I propose three different
parameterizations for the model complexity, and two different methods
for setting the complexity parameter objectively using the data
themselves.  The simplest model-complexity parameter I propose is the
time-spacing of a set of knots for an attitude spline and the simplest
method for setting the complexity I propose is leave-one-out
cross-validation.  I show with toy simulated \gaia-like experiments
that all of my proposed methods out-perform any model complexity
choice established by hand or heuristically; that is, my proposals are
expected to out-perform the default \gaia\ data pipeline plan.
\end{abstract}

\section{introduction}
Here are the points I want to make in this document:

1.~The four-second CCD transit time in \gaia\ has almost nothing to do
with the choice of how frequently there should be ``knots'' or control
points in the data-driven attitude model.  It is true that the mission
is not really sensitive to attitude issues on much smaller time scales
than four seconds, but there might be stability on mych longer time
scales.  This pre-launch choice of knot spacing precludes that kind of
(exceedingly valuable) discovery.

2.~Reducing model complexity, even though it reduces model freedom,
can often \emph{increase} the precision of the results.  The best
results are obtained with the optimal model complexity, where optimal
can be strictly defined in this kind of situation.

3.~The knot spacing---or any model-complexity control
parameter---should be set by an objective process involving either
optimization or marginalization.  It should not be set by intuition.

4.~There are three (easy) options for dealing with this issue:

4a.~Reduce large chunks of the data with different knot spacings (say
four seconds, eight, sixteen, and so on), using leave-one-out (or
really leave-subset-out) cross-validation to assess quality of the
attitude reconstruction in each case.  This is an low-assumption,
easy-to-justify, sensible, frequentist, engineering approach.

4b.~Stick with the current choice of four-second knot spacing, but add
into the least-squares solution a regularization (or prior) term that
prefers to put each knot at the mid-point (in attitude space) between
the adjacent knots.  Adjust the strength of this regularization to
optimize the leave-subset-out cross-validation likelihood or else some
kind of marginalized likelihood.  Or, in an extreme world, marginalize
over it (equivalent to marginalizing out a hyperparameter in a
hierarchical Bayesian model).

4c.~Go to an infinite-dimensional model that has (or really learns)
s/c solid-body physics and a (very large) set of angular impulse
parameters.  Never actually instantiate or report these parameters,
but work in an ``always marginalized'' framework in which only the
(physically motivated) PDF for the angular impulses is learned.  That
is, go hierarchical, learn the hyperparameters, and marginalize out
the infinite number of angular impulses.

Ideally, in this document, if I cared enough to send the very best, I
would:

5.~Build a toy one-dimensional model of the \gaia\ s/c, with a
one-dimensional sky (a ring of stars), active one-axis attitude
control, and an environment of random micro-impulses.

6.~Build a measurement model that reports noisy transit times for the
stars in the toy sky and s/c model.  Create many data sets under
different environment and control assumptions.

7.~Compete the \gaia\ default attitude model plan against the three
options labeled above as 4a, 4b, and 4c.  Show that all three either
match or outperform the default \gaia\ plan for all sets of
assumptions.  Make sure that this is true even when the modeling
assumptions don't match the simulating assumptions.

\section{attitude modeling}

\paragraph{generalities:}
At any s/c time $t$, the \gaia\ s/c has a pseudo-vector orientation
$\theta$.  The orientation can be thought of here as a pseudo-vector
because it can be obtained by integrating an angular velocity.  There
are many time systems in which we can work, but for the purposes of
simplicity, if it matters, I will always mean ``s/c time'' when I
write ``time''.  As the \gaia\ fields of view sweep across the sky,
the s/c produces (for my purposes) a set of $N$ transit time
measurements $t_n$ as the detected stars cross some fiducial reference
line in the focal plane.  In reality things are far more complicated
than this, but I will ignore the complexity because it doesn't change
the overall story.

In particular, the \gaia\ data stream includes both transit times and
across-scan positions (and some PSF information).  However, Lindegren
teaches us (DWH: citation) that most of the information about the sky
and s/c nuisance parameters comes from the transit times.  So the
likelihood given below---which treats the transit times $t_n$ as the
only data---is an approximation, but a good one, especially for my
purposes.

Under the assumption of normally distributed noise contributions to
the transit time measurements $t_n$ with known variances $\sigma^2_n$,
the likelihood is something like
\begin{eqnarray}\displaystyle
p({t_n}_{n=1}^N|\alpha,\gamma,\Theta) &=& \prod_{n=1}^N N(t_n|\tilde{t}_n, \sigma^2_n)
\\
\Theta &\equiv& \left\{\theta_k \right\}_{k=1}^K
\\
\ln p({t_n}_{n=1}^N|\alpha,\gamma,\theta) &=& Q + \frac{1}{2}\,\chi^2
\\
\chi^2 &\equiv& \sum_n \chi^2_n
\\
\chi^2_n &\equiv& \frac{[t_n - \tilde{t}_n]^2}{\sigma^2_n}
\quad ,
\end{eqnarray}
where $\alpha$ is the full list of sky parameters (the celestial
position, parallax, and proper motion of every star), $\gamma$ is the
the full list of global parameters relating to aberration, general
relativity, s/c orbit, solar-system dynamics, and so on, $\Theta$ is
the full list of pseudo-vector angular positions $\theta_k$ or
attitudes at each knot $k$, the $\tilde{t}_n$ are the predicted times
given the sky, global, and angular parameters, the $\sigma^2_n$ are
the (presumed known and correct) noise variances on the $t_n$, the
assumption of independence translates to the product in the likelihood
or the sum $\chi^2$ in the log likelihood, and $Q$ is a constant of no
importance in what follows.

\paragraph{cross-validation:}
The idea in cross-validation is to ``train'' or optimize the model on
most of the data, leaving some out, and then ``test'' or evaluate the
model by having the optimized model predict the left-out data.  The
standard approach in a large data set like that of \gaia\ would be to
assign a random integer $m$ with $1\leq m\leq M$ to every observation
(every transit time $t_n$) and thereby make $M$ ``test'' subsets and
$M$ corresponding ``leave-one-out'' complementary training subsets.
In a full round of cross-validation, the model is optimized to each of
the $M$ leave-one-out training subsets and each of these $M$ optimized
models is used to predict the corresponding left-out test subset.

(DWH: Equations; notation is the big issue here)

\paragraph{regularization model:}
Here we treat the grid of knots $k$ as fixed at times $t_k$---that is
we fix the number of knots $K$ and the knot spacing---but we instead
affect the model complexity by adding to the $\chi^2$ term a
regularization that prefers attitude angles $\theta_k$ that lie close
to half-way between the attitude angles of the adjacent times:
\begin{eqnarray}\displaystyle
\chi^2_\epsilon &\equiv& \chi^2 + \epsilon\,\sum_{k=2}^{K-1} \left[\theta_k - \frac{1}{2}\,[\theta_{k+1} + \theta_{k-1}]\right]^2
\quad ,
\end{eqnarray}
where $\epsilon$ is a regularization parameters setting the influence
of the regularization.  Minimization of $\chi^2_\epsilon$ is
equivalent to maximization of a posterior probability proportional to
the likelihood times a prior that is normal in the pseudo-vector
angular displacements $\theta_k$ away from the means of the adjacent
angles $(1/2)\,[\theta_{k+1}+\theta_{k-1}]$.

(DWH: How is it that we can think of $\epsilon$ as a model-complexity
parameter?)

(DWH: Set $\epsilon$ by cross-validation again.)

(DWH: What would it look like to \emph{marginalize out} the
regularization parameter $\epsilon$.  Almost certainly not worth it.)

\paragraph{impulse model:}
Here we build a physical model for the s/c orientation that involves
angular inertia and random micro-torques.  For simplicity, in what
follows we will assume a rigid s/c (meaning no variation of the moment
of inertia with time), but this can be generalized straightforwardly.
\begin{eqnarray}\displaystyle
L &=& I \cdot \omega
\\
\Delta t_{n-1/2} &\equiv& t_n - t_{n-1}
\\
\theta_n &\leftarrow& \theta_{n-1} + I^{-1}\cdot L_{n-1/2}\,\Delta t_{n-1/2}
\\
L_{n+1/2} &\leftarrow& L_{n-1/2} + \Delta L_n
\quad ,
\end{eqnarray}
where $L$ is the pseudo-vector angular momentum, $I$ is the moment of
inertia tensor, $\omega$ is the pseudo-vector angular velocity,
$\theta_n$ is the orientation of the satellite at time $t_n$, $\Delta
L_n$ is the total pseudo-vector angular impulse in the vicinity of
time $t_n$, and the other variables perform a simple leap-frog
integration scheme.  At every time interval, there is a prior PDF for
the angular impulses, the simplest possible being a normal $N$
(Gaussian)
\begin{eqnarray}\displaystyle
p(\Delta L_n|\delta) &=& N(\Delta L_n|0,D\,\Delta t_n)
\\
\delta &\equiv& \left\{D\right\}
\\
\Delta t_n &\equiv& t_{n+1/2} - t_{n-1/2}
\quad ,
\end{eqnarray}
where $\delta$ represents the full list of ``hyperparameters''
controlling the prior PDF (in this simple case just a variance tensor
$D$), the normal is given a mean of zero because the s/c is
constrained to maintain a constant mean spin rate, and the variance of
the normal is made to grow linearly with time as would be expected for
something like white noise.  A more complicated model would be a
mixture of normals as in
\begin{eqnarray}\displaystyle
p(\Delta L_n|\delta) &=& \sum_{\ell=1}^L A_\ell\,N(\Delta L_n|B_\ell\,\Delta t_n, D_\ell\,\Delta t_n)
\\
1 &=& \sum_{\ell=1}^L A_\ell
\\
0 &=& \sum_{\ell=1}^L A_\ell\,B_\ell
\\
\delta &\equiv& \left\{A_\ell, B_\ell, D_\ell\right\}_{\ell=1}^L
\quad ,
\end{eqnarray}
where the $A_\ell$ are scalars, the $B_\ell$ are peudo-vectors, the
$D_\ell$ are tensors, the $B_\ell$ average to zero to maintain s/c
scan rate, and both the means and the variances of the components rise
with time (DWH: Does this makes sense?).

(DWH: Note about working at the \emph{observed} times $t_n$ rather
than on some other grid.)

\section{toy model}

(DWH: sky is a poisson sample of S stars)

(DWH: global parameters are null:  No SR, no GR, nothing.)

(DWH: attitude is affected by four things: steady torque, white noise,
periodic s/c control impulses, and random impulses.)

\section{experiments and results}

\section{discussion}

\paragraph{acknowledgments:}
It is a pleasure to thank Berry Holl (Lund) and Lennart Lindegren
(Lund) for getting me to think about these things, and Coryn
Bailer-Jones (MPIA), Jo Bovy (IAS), Anthony Brown (Leiden), Iain
Murray (Edinburgh), and Sam Roweis (deceased) for valuable
discussions.

\end{document}
